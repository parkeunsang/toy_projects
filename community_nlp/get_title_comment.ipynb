{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import os\n",
    "import pymysql\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_address = os.environ['AWS_IP']\n",
    "PASSWORD = os.environ['SQL_PWD_AWS']\n",
    "\n",
    "con = pymysql.connect(\n",
    "    user='edward', \n",
    "    passwd=PASSWORD,\n",
    "    host=ip_address, \n",
    "    db='community', \n",
    "    charset='utf8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://pann.nate.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuos_dates(start, end, fm):\n",
    "    dates = []\n",
    "    dt = datetime.datetime.strptime(start, fm)\n",
    "    while True:\n",
    "        dt_string = dt.strftime(format=fm)\n",
    "        dates.append(dt_string)\n",
    "        if dt_string == end:\n",
    "            break\n",
    "        dt = dt + datetime.timedelta(days=1)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(date):\n",
    "    # %Y-%m-%d\n",
    "    sql = f\"select * from urls where date = '{date}'\"\n",
    "    with con.cursor() as cursor:\n",
    "        cursor.execute(sql)\n",
    "        result = cursor.fetchall()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dup_content(article_id):\n",
    "    sql = f\"select * from nate_content where id = {article_id}\"\n",
    "    with  con.cursor() as cursor:\n",
    "        cursor.execute(sql)\n",
    "#     return bool(cursor.fetchall())\n",
    "    return cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_content(values):\n",
    "    sql = f'insert into nate_content(id, title, content, date) values {values}'\n",
    "    with  con.cursor() as cursor:\n",
    "        cursor.execute(sql)\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_comment(values):\n",
    "    sql = f'insert into nate_comment(good, bad, content, article_id) values {values}'\n",
    "    with  con.cursor() as cursor:\n",
    "        cursor.execute(sql)\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = continuos_dates('2021-01-02', '2021-01-10', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 'nate_pann', '/talk/356809550', datetime.date(2021, 1, 10))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:16<00:00,  1.31it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:14<00:00,  1.35it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:14<00:00,  1.34it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:16<00:00,  1.31it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:14<00:00,  1.34it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:10<00:00,  1.42it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:11<00:00,  1.41it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:15<00:00,  1.33it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:15<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for date in dates:\n",
    "    print(date)\n",
    "    urls = get_urls(date)\n",
    "    for u in tqdm(urls):\n",
    "        # 글 내용 저장\n",
    "        article_id, kind, url_tail, date = u\n",
    "        if is_dup_content(article_id):  # 이미 db에 저장되어있으면\n",
    "            continue\n",
    "        url = BASE_URL + url_tail\n",
    "        soup = BeautifulSoup(requests.get(url).text, 'lxml')\n",
    "        title = soup.find('title').text\n",
    "        content = soup.find('div', {'id': 'contentArea'}).text.strip()\n",
    "        values = (article_id, title, content, date.strftime('%Y-%m-%d'))\n",
    "        commit_content(values)\n",
    "\n",
    "        # 댓글 저장\n",
    "        comments = soup.find('div', {'class':'commentBox'}).find_all('dl', {'class': 'cmt_item'})\n",
    "        for comment in comments:\n",
    "            if len(comment.find_all('dt')) <= 1:  # 삭제된 댓글\n",
    "                continue\n",
    "\n",
    "            good = int(comment.find('dd', {'class': 'n_good'}).text) \n",
    "            bad = int(comment.find('dd', {'class': 'n_bad'}).text) \n",
    "            cm = comment.find('dd', {'class': 'usertxt'}).text.strip()\n",
    "            values = (good, bad, cm, article_id)\n",
    "            commit_comment(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
