{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oa9P_L6ozzH"
   },
   "source": [
    "https://tutorials.pytorch.kr/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlBpGdzqo_Eu",
    "outputId": "d4d5cdb1-f9ea-42b1-e589-bf3953284b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at ./mount\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "drive.mount('./mount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGn0ktFSqZs0"
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDXojGFjqax_"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3quxkenAptai"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEuNbTaYRiDD"
   },
   "outputs": [],
   "source": [
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, max_smiles_length, additional_features_count, dropout, use_mask=False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K24Kb71SRZq4",
    "outputId": "8fdf7225-98f5-40bd-f7aa-44ddd3be43bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 18, 40])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward_before_fc(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ycau0OvlRcwV",
    "outputId": "4c43eba5-39d4-4a42-b504-66d4e4bb2baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 18, 40])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward_before_fc_nomask(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2oO5UJpQ1KG"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, d_model, nhead, d_hid,\n",
    "                 nlayers, max_smiles_length, additional_features_count, dropout = 0.5, use_mask=True):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_smiles_length, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.use_mask = use_mask\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc1 = nn.Linear(d_model, 1)  # MLM or HLM 값 하나를 예측\n",
    "        self.fc2 = nn.Linear(max_smiles_length+additional_features_count, 128)  # middle layer\n",
    "        self.fc3 = nn.Linear(128, 64)  # middle layer\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "        self.bn2 = torch.nn.BatchNorm1d(128)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(64)\n",
    "        self.init_weights()\n",
    "\n",
    "    def get_mask(self, src):\n",
    "        mask = src == 0\n",
    "        return mask.transpose(0, 1).to(DEVICE)\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.bias.data.zero_()\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc3.bias.data.zero_()\n",
    "        self.fc3.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc4.bias.data.zero_()\n",
    "        self.fc4.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_numeric) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        mask = self.get_mask(src)\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if self.use_mask:\n",
    "            output = self.transformer_encoder(src, src_key_padding_mask=mask)\n",
    "        else:\n",
    "            output = self.transformer_encoder(src)\n",
    "        output = self.fc1(output)\n",
    "        output = output.transpose(0, 2)[0]  # [0]: (1, 18, 100) -> (18, 100)\n",
    "        output = torch.cat([output, src_numeric.transpose(0, 1)], axis=1)\n",
    "        # output = self.gelu(self.bn2(self.fc2(output)))\n",
    "        # output = self.gelu(self.bn3(self.fc3(output)))\n",
    "        output = self.gelu(self.fc2(output))\n",
    "        output = self.gelu(self.fc3(output))\n",
    "        output = self.fc4(output)\n",
    "        return output\n",
    "\n",
    "    def forward_embed(self, src):\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        return src\n",
    "\n",
    "    def forward_before_fc(self, src):\n",
    "        mask = self.get_mask(src)\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_key_padding_mask=mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9B_RQNapx2k"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_axX3qsrVZa"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyvSePnUr_iP"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZG6H651o9ubr"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHQ3Yi61spi7"
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, smiles_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            smiles_list (list): DataFrame의 SMILES Columns\n",
    "        \"\"\"\n",
    "        self.smiles_list = smiles_list\n",
    "        self.get_token_map()\n",
    "\n",
    "    def get_token_map(self):\n",
    "        token_count = []\n",
    "        for smiles in self.smiles_list:\n",
    "            smiles_sep = list(smiles)  # 'CCO' --> ['C', 'C', 'O']\n",
    "            token_count.extend(smiles_sep)\n",
    "        token_count = Counter(token_count)\n",
    "        self.token_map = {}\n",
    "        self.token_map['<pad>'] = 0\n",
    "        for idx, k in enumerate(token_count, start=1):\n",
    "            self.token_map[k] = idx\n",
    "        self.unk = idx + 1  # unknown idx\n",
    "\n",
    "    def tokenize(self, smiles):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            smiles (list): ex) ['C', 'C', 'O', '1', '<pad>', '<pad>' ,...]\n",
    "        \"\"\"\n",
    "        tokenized_list = []\n",
    "        for s in smiles:\n",
    "            token_idx = self.token_map.get(s, self.unk)  # map에 없는 값일 경우 self.unk(=33) 할당\n",
    "            tokenized_list.append(token_idx)\n",
    "        return tokenized_list\n",
    "\n",
    "    def token_count(self):\n",
    "        return self.unk + 1  # 0부터 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBGKajqa9t2b",
    "outputId": "4eb2580b-e396-4cbc-9a31-782f77c13684"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2998])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMWyEI9HAIPY",
    "outputId": "1f448329-da4b-44fb-b825-90457143c83a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2998])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(df_train_numeric, dtype=torch.float64).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSwBr45sACrf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--wBNUYqsZRa"
   },
   "outputs": [],
   "source": [
    "class SmilesDataset(Dataset):\n",
    "    def __init__(self, df, df_numeric, target_column, tokenizer, max_smiles_length, batch_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df_numeric (np.array): 데이터에서 추가로 사용할 설명변수\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_smiles_length = max_smiles_length\n",
    "        self.batch_size = batch_size\n",
    "        self.smiles_to_tokens(df['SMILES'].tolist())\n",
    "        # torch.int16이 아닌 long(=int64)을 쓰는 이유는 embedding에서 long밖에 받지 못하기 때문\n",
    "        self.X = torch.tensor(self.X, dtype=torch.long).transpose(0, 1)  # max_smiles_length by 데이터 개수. train data의 경우 100 x 3498\n",
    "        self.X_numeric = torch.tensor(df_numeric, dtype=torch.float32).transpose(0, 1)\n",
    "        self.y = df[target_column].tolist()\n",
    "        self.y = torch.tensor(self.y, dtype=torch.float32).unsqueeze(1)  # train data의 경우 3498 x 1\n",
    "\n",
    "    def smiles_to_tokens(self, smiles_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            smiles_list (list): DataFrame의 SMILES Columns\n",
    "        Returns:\n",
    "            token_data (list-2d): (data 개수) by (max_smiles_length)\n",
    "        \"\"\"\n",
    "        self.X = []\n",
    "        for smiles in smiles_list:\n",
    "            smiles_padded = list(smiles[:self.max_smiles_length])\n",
    "            padding_count = self.max_smiles_length - len(smiles_padded)  # <pad> 개수\n",
    "            padding_list = ['<pad>'] * padding_count  # if padding_count == 0, then padding_list = []\n",
    "            smiles_padded.extend(padding_list)\n",
    "            tokens = self.tokenizer.tokenize(smiles_padded)  # 길이가 100인 list. ex) [1, 2, 0, ...., 33]\n",
    "            self.X.append(tokens)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = i*self.batch_size\n",
    "        X = self.X[:, idx:idx+self.batch_size]\n",
    "        X_numeric = self.X_numeric[:, idx:idx+self.batch_size]\n",
    "        y = self.y[idx:idx+self.batch_size]\n",
    "        return X.to(DEVICE), X_numeric.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHkR3NN8n_hY",
    "outputId": "09542f1c-d4fe-4c72-c46e-88bf1cad6a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/mount/MyDrive/study/transformer\n"
     ]
    }
   ],
   "source": [
    "cd /content/mount/MyDrive/study/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiCYKyyCnSbn"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxT2B1AIn9Wf"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zq-nmU1oF5h",
    "outputId": "00d82333-2f9b-4b06-e2c2-16b446a412af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 33, 0]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(['C', '(', '%', '<pad>']) # '%'는 없는 토큰이므로 33을 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "MWDZ_ZM3oGRc",
    "outputId": "fdac173a-78e2-48ba-ac6d-ff04b9eef008"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['SMILES'].str.len().plot(kind='hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X83fofZzF5Tn"
   },
   "outputs": [],
   "source": [
    "train['AlogP'] = train['AlogP'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdVub1CW3zIb"
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train[:3000], train[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgjBokOf3aC8"
   },
   "outputs": [],
   "source": [
    "smiles_unique_count = train.groupby('SMILES').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5iJQLY73kPa"
   },
   "outputs": [],
   "source": [
    "smiles_test = smiles_unique_count[smiles_unique_count == 1].sample(500, random_state=42).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9ioSKlJ34fF"
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train[~train['SMILES'].isin(smiles_test)], train[train['SMILES'].isin(smiles_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5l1npMwk_cER"
   },
   "source": [
    "#### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UED0NSXm_bke"
   },
   "outputs": [],
   "source": [
    "scale_columns = ['AlogP', 'Molecular_Weight',\n",
    "       'Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'LogD',\n",
    "       'Molecular_PolarSurfaceArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dX7OW1MD_bhF"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_train_numeric = scaler.fit_transform(df_train[scale_columns])\n",
    "df_val_numeric = scaler.transform(df_val[scale_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LPuHhZW_0zs",
    "outputId": "b2d3fbb7-4ea0-4d9c-9245-fbcb771d78b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2998, 7) (500, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_numeric.shape, df_val_numeric.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNX-r_qcHuMs"
   },
   "outputs": [],
   "source": [
    "# max_smiles_length = train['SMILES'].str.len().max()  # 174\n",
    "max_smiles_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peSpbFOb4MoC"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(df_train['SMILES'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSFGLMmI2ZIA"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "target_column = 'HLM'\n",
    "train_data = SmilesDataset(df_train, df_train_numeric, target_column, tokenizer, max_smiles_length, 20)\n",
    "\n",
    "val_data = SmilesDataset(df_val, df_val_numeric, target_column, tokenizer, max_smiles_length, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpkkUS2o6H57"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eeb7gycXNuXk"
   },
   "source": [
    "https://aladdinpersson.medium.com/how-to-get-a-progress-bar-in-pytorch-72bdbf19b35c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-lMcIdVNzjv"
   },
   "outputs": [],
   "source": [
    "# v11: 1060, 30\n",
    "ntokens = tokenizer.token_count() # Token size\n",
    "emsize = 40 # 임베딩 차원  # 어차피 단어한개라서 임베딩사이즈를 키움안되는구나\n",
    "d_hid = 100 # ``nn.TransformerEncoder`` 에서 피드포워드 네트워크(feedforward network) 모델의 차원\n",
    "nlayers = 2 # ``nn.TransformerEncoder`` 내부의 nn.TransformerEncoderLayer 개수\n",
    "nhead = 2 # ``nn.MultiheadAttention`` 의 헤드 개수\n",
    "additional_features_count = df_train_numeric.shape[1]  # 7\n",
    "dropout = 0.1 # 드랍아웃(dropout) 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5jPWC08Xd5B"
   },
   "outputs": [],
   "source": [
    "# v11:\n",
    "ntokens = tokenizer.token_count() # Token size\n",
    "emsize = 10 # 임베딩 차원  # 어차피 단어한개라서 임베딩사이즈를 키움안되는구나\n",
    "d_hid = 50 # ``nn.TransformerEncoder`` 에서 피드포워드 네트워크(feedforward network) 모델의 차원\n",
    "nlayers = 2 # ``nn.TransformerEncoder`` 내부의 nn.TransformerEncoderLayer 개수\n",
    "nhead = 2 # ``nn.MultiheadAttention`` 의 헤드 개수\n",
    "additional_features_count = df_train_numeric.shape[1]  # 7\n",
    "dropout = 0.1 # 드랍아웃(dropout) 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLdA25_27AOS"
   },
   "outputs": [],
   "source": [
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, max_smiles_length, additional_features_count, dropout, use_mask=False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8ccf2iRfWZW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-D42G7AF8agM"
   },
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.HuberLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2kP1Kc5Nqrb"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTL-2e8gCftj",
    "outputId": "829f770b-022a-45f5-8b05-e5048d2a1c00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]: 100%|██████████| 150/150 [00:01<00:00, 82.38it/s, loss=4.03e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 3680.50345703125 3680.50345703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]: 100%|██████████| 150/150 [00:01<00:00, 81.42it/s, loss=2.58e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1436.90115234375 1436.90115234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]: 100%|██████████| 150/150 [00:01<00:00, 77.27it/s, loss=1.29e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1270.5697021484375 1270.5697021484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]: 100%|██████████| 150/150 [00:02<00:00, 68.86it/s, loss=1.25e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1242.2838793945311 1242.2838793945311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]: 100%|██████████| 150/150 [00:02<00:00, 68.79it/s, loss=1.22e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1208.0026123046875 1208.0026123046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]: 100%|██████████| 150/150 [00:01<00:00, 83.79it/s, loss=1.19e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1174.6584252929688 1174.6584252929688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]: 100%|██████████| 150/150 [00:01<00:00, 82.03it/s, loss=1.17e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1147.0414135742187 1147.0414135742187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]: 100%|██████████| 150/150 [00:01<00:00, 80.05it/s, loss=1.15e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1125.6057006835938 1125.6057006835938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/30]: 100%|██████████| 150/150 [00:01<00:00, 80.22it/s, loss=1.13e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1109.8106982421875 1109.8106982421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]: 100%|██████████| 150/150 [00:01<00:00, 79.33it/s, loss=1.12e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1098.64296875 1098.64296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]: 100%|██████████| 150/150 [00:02<00:00, 73.32it/s, loss=1.12e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1090.9344470214844 1090.9344470214844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]: 100%|██████████| 150/150 [00:02<00:00, 65.71it/s, loss=1.11e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1085.6352905273438 1085.6352905273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]: 100%|██████████| 150/150 [00:01<00:00, 81.32it/s, loss=1.11e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1081.9796826171876 1081.9796826171876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]: 100%|██████████| 150/150 [00:01<00:00, 81.37it/s, loss=1.11e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1079.3917602539063 1079.3917602539063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]: 100%|██████████| 150/150 [00:01<00:00, 81.17it/s, loss=1.11e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1077.5341455078126 1077.5341455078126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]: 100%|██████████| 150/150 [00:01<00:00, 81.22it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1076.1595385742187 1076.1595385742187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]: 100%|██████████| 150/150 [00:01<00:00, 80.89it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1075.0885021972656 1075.0885021972656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]: 100%|██████████| 150/150 [00:02<00:00, 71.93it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1074.2483410644531 1074.2483410644531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]: 100%|██████████| 150/150 [00:02<00:00, 66.67it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1073.5342248535155 1073.5342248535155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]: 100%|██████████| 150/150 [00:02<00:00, 71.12it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1072.9341442871093 1072.9341442871093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/30]: 100%|██████████| 150/150 [00:01<00:00, 78.14it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1072.424736328125 1072.424736328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]: 100%|██████████| 150/150 [00:01<00:00, 79.34it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1071.9551525878906 1071.9551525878906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]: 100%|██████████| 150/150 [00:01<00:00, 78.38it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1071.52484375 1071.52484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]: 100%|██████████| 150/150 [00:01<00:00, 77.01it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1071.1098693847657 1071.1098693847657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]: 100%|██████████| 150/150 [00:02<00:00, 71.32it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1070.733779296875 1070.733779296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]: 100%|██████████| 150/150 [00:02<00:00, 67.30it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1070.3789990234375 1070.3789990234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/30]: 100%|██████████| 150/150 [00:02<00:00, 70.79it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1070.0175048828125 1070.0175048828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]: 100%|██████████| 150/150 [00:01<00:00, 80.59it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1069.6776440429687 1069.6776440429687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]: 100%|██████████| 150/150 [00:01<00:00, 77.87it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1069.3261462402343 1069.3261462402343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/30]: 100%|██████████| 150/150 [00:01<00:00, 79.83it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1068.9934680175782 1068.9934680175782\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    loss_log = []\n",
    "    loop = tqdm(range(len(train_data) + 1))\n",
    "    for i in loop:\n",
    "        X, X_numeric, y = train_data[i][0], train_data[i][1], train_data[i][2]\n",
    "        if X.shape[-1] == 0:  # train data size % batch size == 0일때, 마지막 iter의 X는 길이가 0이 됨.\n",
    "            continue\n",
    "        output = model(X, X_numeric)\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_log.append(loss.item())\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]\")\n",
    "        loop.set_postfix(loss=np.mean(loss_log))\n",
    "    # Validate\n",
    "    _loss_log = []\n",
    "    _loss_log_target = []  # mse\n",
    "    model.eval()\n",
    "    for j in range(len(val_data)+1):\n",
    "        _X, _X_numeric, _y = val_data[j][0], val_data[j][1], val_data[j][2]\n",
    "        if _X.shape[-1] == 0:  # train data size % batch size == 0일때, 마지막 iter의 X는 길이가 0이 됨.\n",
    "            continue\n",
    "        with torch.no_grad():\n",
    "            _output = model(_X, _X_numeric)\n",
    "        _loss = criterion(_output, _y)\n",
    "        _loss_mse = mse_loss(_output, _y)\n",
    "        _loss_log.append(_loss.item())\n",
    "        _loss_log_target.append(_loss_mse.item())\n",
    "    print('val loss:', np.mean(_loss_log_target), np.mean(_loss_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XD1gfyU_sQz3"
   },
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odKOiKLluHYs"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajYqs_zQvmoG"
   },
   "outputs": [],
   "source": [
    "test['MLM'] = 0\n",
    "test['HLM'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ4uRwrTTt9N"
   },
   "outputs": [],
   "source": [
    "train['AlogP'] = train['AlogP'].fillna(train['AlogP'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gazgkC3fTzWO"
   },
   "outputs": [],
   "source": [
    "test['AlogP'] = test['AlogP'].fillna(train['AlogP'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSLrJQYfTdFZ"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_numeric = scaler.fit_transform(train[scale_columns])\n",
    "test_numeric = scaler.transform(test[scale_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbmY1qSQsRnx"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_data_mlm = SmilesDataset(train, train_numeric, 'MLM', tokenizer, max_smiles_length, 20)\n",
    "train_data_hlm = SmilesDataset(train, train_numeric, 'HLM', tokenizer, max_smiles_length, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uK1b-spDvs7P"
   },
   "outputs": [],
   "source": [
    "test_data_mlm = SmilesDataset(test, test_numeric, 'MLM', tokenizer, max_smiles_length, 20)\n",
    "test_data_hlm = SmilesDataset(test, test_numeric, 'HLM', tokenizer, max_smiles_length, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJ9SfeAlvWlD"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(train['SMILES'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfkJ3ZCLvZ9m"
   },
   "outputs": [],
   "source": [
    "ntokens = tokenizer.token_count() # Token size\n",
    "emsize = 100 # 임베딩 차원\n",
    "d_hid = 200 # ``nn.TransformerEncoder`` 에서 피드포워드 네트워크(feedforward network) 모델의 차원\n",
    "nlayers = 2 # ``nn.TransformerEncoder`` 내부의 nn.TransformerEncoderLayer 개수\n",
    "nhead = 2 # ``nn.MultiheadAttention`` 의 헤드 개수\n",
    "dropout = 0.1 # 드랍아웃(dropout) 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxhksAbPT-46"
   },
   "outputs": [],
   "source": [
    "# v11: 1060, 30\n",
    "ntokens = tokenizer.token_count() # Token size\n",
    "emsize = 40 # 임베딩 차원  # 어차피 단어한개라서 임베딩사이즈를 키움안되는구나\n",
    "d_hid = 100 # ``nn.TransformerEncoder`` 에서 피드포워드 네트워크(feedforward network) 모델의 차원\n",
    "nlayers = 2 # ``nn.TransformerEncoder`` 내부의 nn.TransformerEncoderLayer 개수\n",
    "nhead = 2 # ``nn.MultiheadAttention`` 의 헤드 개수\n",
    "additional_features_count = df_train_numeric.shape[1]  # 7\n",
    "dropout = 0.1 # 드랍아웃(dropout) 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2BAJ9FAvbLF"
   },
   "outputs": [],
   "source": [
    "model_mlm = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, max_smiles_length, additional_features_count, dropout, use_mask=False).to(DEVICE)\n",
    "model_hlm = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, max_smiles_length, additional_features_count, dropout, use_mask=False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yexfovpvcdl"
   },
   "outputs": [],
   "source": [
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_mlm = torch.optim.AdamW(model_mlm.parameters(), lr=1e-4)\n",
    "optimizer_hlm = torch.optim.AdamW(model_hlm.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Eiq43dBv3ib"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCski0ewxFGf",
    "outputId": "71466d53-bdbc-402a-9447-0a5455e7006e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/30]: 100%|██████████| 175/175 [00:02<00:00, 67.14it/s, loss=2.21e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]: 100%|██████████| 175/175 [00:02<00:00, 58.55it/s, loss=1.27e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]: 100%|██████████| 175/175 [00:02<00:00, 64.86it/s, loss=1.25e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]: 100%|██████████| 175/175 [00:02<00:00, 60.69it/s, loss=1.23e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]: 100%|██████████| 175/175 [00:02<00:00, 66.94it/s, loss=1.21e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]: 100%|██████████| 175/175 [00:02<00:00, 63.23it/s, loss=1.19e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]: 100%|██████████| 175/175 [00:02<00:00, 80.76it/s, loss=1.17e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]: 100%|██████████| 175/175 [00:02<00:00, 80.10it/s, loss=1.15e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]: 100%|██████████| 175/175 [00:02<00:00, 78.96it/s, loss=1.13e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/30]: 100%|██████████| 175/175 [00:03<00:00, 49.01it/s, loss=1.11e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]: 100%|██████████| 175/175 [00:03<00:00, 51.21it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]: 100%|██████████| 175/175 [00:02<00:00, 68.70it/s, loss=1.09e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]: 100%|██████████| 175/175 [00:02<00:00, 76.40it/s, loss=1.09e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]: 100%|██████████| 175/175 [00:02<00:00, 77.19it/s, loss=1.08e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]: 100%|██████████| 175/175 [00:02<00:00, 79.52it/s, loss=1.08e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]: 100%|██████████| 175/175 [00:02<00:00, 75.41it/s, loss=1.08e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]: 100%|██████████| 175/175 [00:02<00:00, 66.08it/s, loss=1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]: 100%|██████████| 175/175 [00:02<00:00, 66.12it/s, loss=1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]: 100%|██████████| 175/175 [00:02<00:00, 76.79it/s, loss=1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]: 100%|██████████| 175/175 [00:02<00:00, 79.64it/s, loss=1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]: 100%|██████████| 175/175 [00:02<00:00, 78.71it/s, loss=1.06e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/30]: 100%|██████████| 175/175 [00:02<00:00, 75.90it/s, loss=1.06e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]: 100%|██████████| 175/175 [00:04<00:00, 43.62it/s, loss=1.05e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]: 100%|██████████| 175/175 [00:02<00:00, 65.19it/s, loss=1.05e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]: 100%|██████████| 175/175 [00:02<00:00, 76.30it/s, loss=1.05e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]: 100%|██████████| 175/175 [00:02<00:00, 75.50it/s, loss=1.04e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]: 100%|██████████| 175/175 [00:02<00:00, 76.78it/s, loss=1.04e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/30]: 100%|██████████| 175/175 [00:02<00:00, 72.68it/s, loss=1.03e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]: 100%|██████████| 175/175 [00:02<00:00, 67.53it/s, loss=1.03e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]: 100%|██████████| 175/175 [00:02<00:00, 66.70it/s, loss=1.03e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model_mlm.train()\n",
    "    loss_log = []\n",
    "    loop = tqdm(range(len(train_data_mlm) + 1))\n",
    "    for i in loop:\n",
    "        X, X_numeric, y = train_data_mlm[i][0], train_data_mlm[i][1], train_data_mlm[i][2]\n",
    "        if X.shape[-1] == 0:  # train data size % batch size == 0일때, 마지막 iter의 X는 길이가 0이 됨.\n",
    "            continue\n",
    "        output = model_mlm(X, X_numeric)\n",
    "        loss = criterion(output, y)\n",
    "        optimizer_mlm.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_mlm.step()\n",
    "        loss_log.append(loss.item())\n",
    "\n",
    "        loop.set_description(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "        loop.set_postfix(loss=np.mean(loss_log))\n",
    "    if np.mean(loss_log) < best_loss:\n",
    "        print('saved model')\n",
    "        torch.save(model_mlm.state_dict(), 'checkpoint/model_mlm.pt')\n",
    "        best_loss = np.mean(loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzAaFPn8wfP9",
    "outputId": "5ea5cac5-e80a-47ea-8842-acfab1a800af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/30]: 100%|██████████| 175/175 [00:02<00:00, 80.64it/s, loss=3.23e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]: 100%|██████████| 175/175 [00:02<00:00, 80.32it/s, loss=1.31e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]: 100%|██████████| 175/175 [00:02<00:00, 80.45it/s, loss=1.27e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]: 100%|██████████| 175/175 [00:02<00:00, 79.63it/s, loss=1.25e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]: 100%|██████████| 175/175 [00:02<00:00, 72.54it/s, loss=1.23e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]: 100%|██████████| 175/175 [00:02<00:00, 65.25it/s, loss=1.21e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]: 100%|██████████| 175/175 [00:02<00:00, 70.73it/s, loss=1.18e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]: 100%|██████████| 175/175 [00:02<00:00, 79.96it/s, loss=1.16e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]: 100%|██████████| 175/175 [00:02<00:00, 80.48it/s, loss=1.15e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/30]: 100%|██████████| 175/175 [00:02<00:00, 79.30it/s, loss=1.14e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]: 100%|██████████| 175/175 [00:02<00:00, 77.27it/s, loss=1.13e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]: 100%|██████████| 175/175 [00:02<00:00, 66.21it/s, loss=1.12e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]: 100%|██████████| 175/175 [00:02<00:00, 68.54it/s, loss=1.11e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]: 100%|██████████| 175/175 [00:02<00:00, 80.49it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]: 100%|██████████| 175/175 [00:02<00:00, 78.71it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]: 100%|██████████| 175/175 [00:02<00:00, 78.58it/s, loss=1.1e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]: 100%|██████████| 175/175 [00:02<00:00, 78.32it/s, loss=1.09e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]: 100%|██████████| 175/175 [00:02<00:00, 64.02it/s, loss=1.09e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]: 100%|██████████| 175/175 [00:02<00:00, 64.28it/s, loss=1.09e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]: 100%|██████████| 175/175 [00:02<00:00, 77.35it/s, loss=1.08e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]: 100%|██████████| 175/175 [00:02<00:00, 78.03it/s, loss=1.09e+3]\n",
      "Epoch [21/30]: 100%|██████████| 175/175 [00:02<00:00, 78.60it/s, loss=1.08e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]: 100%|██████████| 175/175 [00:02<00:00, 78.73it/s, loss=1.08e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]: 100%|██████████| 175/175 [00:02<00:00, 67.11it/s, loss=1.08e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]: 100%|██████████| 175/175 [00:02<00:00, 63.95it/s, loss=1.08e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]: 100%|██████████| 175/175 [00:02<00:00, 77.70it/s, loss=1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]: 100%|██████████| 175/175 [00:02<00:00, 76.14it/s, loss=1.07e+3]\n",
      "Epoch [27/30]: 100%|██████████| 175/175 [00:02<00:00, 79.08it/s, loss=1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]: 100%|██████████| 175/175 [00:02<00:00, 78.76it/s, loss=1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]: 100%|██████████| 175/175 [00:02<00:00, 72.92it/s, loss=1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model_hlm.train()\n",
    "    loss_log = []\n",
    "    loop = tqdm(range(len(train_data_hlm) + 1))\n",
    "    for i in loop:\n",
    "        X, X_numeric, y = train_data_hlm[i][0], train_data_hlm[i][1], train_data_hlm[i][2]\n",
    "        if X.shape[-1] == 0:  # train data size % batch size == 0일때, 마지막 iter의 X는 길이가 0이 됨.\n",
    "            continue\n",
    "        output = model_hlm(X, X_numeric)\n",
    "        loss = criterion(output, y)\n",
    "        optimizer_hlm.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_hlm.step()\n",
    "        loss_log.append(loss.item())\n",
    "\n",
    "        loop.set_description(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "        loop.set_postfix(loss=np.mean(loss_log))\n",
    "    if np.mean(loss_log) < best_loss:\n",
    "        print('saved model')\n",
    "        torch.save(model_hlm.state_dict(), 'checkpoint/model_hlm.pt')\n",
    "        best_loss = np.mean(loss_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHcZxXHgxObo"
   },
   "source": [
    "### make file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hL4Rd7ZHy7Ft"
   },
   "outputs": [],
   "source": [
    "model_mlm = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, max_smiles_length, additional_features_count, dropout, use_mask=False).to(DEVICE)\n",
    "model_hlm = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, max_smiles_length, additional_features_count, dropout, use_mask=False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlQPg3jjy7xu",
    "outputId": "4c74c05e-6c91-4a30-9837-4946aedb0b18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_mlm = torch.load('checkpoint/model_mlm.pt')\n",
    "weights_hlm = torch.load('checkpoint/model_hlm.pt')\n",
    "model_mlm.load_state_dict(weights_mlm)\n",
    "model_hlm.load_state_dict(weights_hlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKxTq9ggxlwO"
   },
   "outputs": [],
   "source": [
    "mlm_pred = []\n",
    "hlm_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0L56tCfxfe8"
   },
   "outputs": [],
   "source": [
    "model_mlm.eval()\n",
    "for j in range(len(test_data_mlm)+1):\n",
    "    _X, _X_numeric = test_data_mlm[j][0], test_data_mlm[j][1]\n",
    "    with torch.no_grad():\n",
    "        _output = model_mlm(_X, _X_numeric)\n",
    "        _output = _output.squeeze().tolist()\n",
    "        mlm_pred.extend(_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jplMo3EqzgMJ"
   },
   "outputs": [],
   "source": [
    "model_hlm.eval()\n",
    "for j in range(len(test_data_hlm)+1):\n",
    "    _X, _X_numeric = test_data_mlm[j][0], test_data_mlm[j][1]\n",
    "    with torch.no_grad():\n",
    "        _output = model_hlm(_X, _X_numeric)\n",
    "        _output = _output.squeeze().tolist()\n",
    "        hlm_pred.extend(_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFEKiDfsxPjf"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2bZlPj6yaKn"
   },
   "outputs": [],
   "source": [
    "submission['MLM'] = train['MLM'].mean()\n",
    "submission['HLM'] = train['HLM'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7qvjMXNygXJ"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3jrajVtzmwU"
   },
   "outputs": [],
   "source": [
    "submission['MLM'] = mlm_pred\n",
    "submission['HLM'] = hlm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ErdU2SMzyXw",
    "outputId": "849c64a7-3820-4738-a4fa-56ff1ae230dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['HLM'] < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeGk6IgHzpRk",
    "outputId": "6f8e98b6-bf1b-467f-8ffd-73ff27235701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n"
     ]
    }
   ],
   "source": [
    "print(sum(submission['MLM'] < 0), sum(submission['HLM'] < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-B3sHUmz5P5"
   },
   "outputs": [],
   "source": [
    "submission.loc[submission['HLM'] < 0, 'HLM'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_EtC8wEz-ny",
    "outputId": "eee6d846-45dc-4cbc-c28b-571ec3902b53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n"
     ]
    }
   ],
   "source": [
    "print(sum(submission['MLM'] < 0), sum(submission['HLM'] < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ta99s04-z9-P"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8PE8o7L0CMw",
    "outputId": "8f77aef9-8302-4038-8b67-7867a4eb0fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcheckpoint\u001b[0m/  seq_to_seq.ipynb  stock.ipynb        submission_v2.csv\n",
      "\u001b[01;34mdata\u001b[0m/        smiles.ipynb      submission_v1.csv  Untitled0.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
